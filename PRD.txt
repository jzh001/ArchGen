Product Requirements Document (PRD)

Project Name: ArchGen

1. Overview

The goal of this project is to build a Gradio-based web interface, hosted on Hugging Face Spaces, that allows researchers to paste or upload PyTorch nn.Module code and automatically generate a clean, professional neural network architecture diagram. This diagram should be suitable for inclusion in academic papers, presentations, and technical reports.

Unlike traditional rule-based tools, ArchGen leverages Large Language Models (LLMs) to intelligently format and present diagrams in an academic style, while still supporting deterministic backends (e.g., Graphviz, torchviz) as fallbacks.

2. Objectives & Goals

Provide an easy-to-use interface for researchers who want to visualize neural networks defined in PyTorch.

Use LLM workflows (LangChain / LangGraph / llama_index) to generate professional academic-quality diagrams, automatically improving clarity and layout.

Allow user-controlled regeneration of diagrams if the output is unsatisfactory.

Support choice of LLM providers, including:

Hosted APIs (e.g., OpenAI, Anthropic, TogetherAI).

Self-hosted/local models via Ollama.

Generate diagrams in multiple export formats: PNG, PDF, JPEG.

Ensure compatibility with Hugging Face Spaces (Gradio + lightweight backend).

3. Target Audience

Academic researchers writing machine learning papers.

Students preparing research presentations.

Developers documenting neural network architectures.

4. User Stories

As a researcher, I want to paste my nn.Module code and receive a professional diagram, formatted like figures in ICML/NeurIPS papers.

As a PhD student, I want to regenerate the diagram with one click until I am satisfied.

As a developer, I want to choose which LLM generates my diagram (e.g., OpenAI GPT-4, local Llama2 via Ollama).

As a user, I want to securely provide my own API key if using a cloud LLM, or run locally without internet.

As a LaTeX user, I want the option to download a TikZ/PGF representation of the diagram.

5. Key Features
5.1 Input

Text box for pasting nn.Module Python code.

Optional file upload (.py).

Optional selection of preset models (ResNet, Transformer, LSTM).

LLM selection dropdown (OpenAI, Anthropic, HuggingFace Hub models, Ollama).

API key input box (hidden/secured, only stored in session).

5.2 Processing

Step 1: Code Parsing

Parse PyTorch code using torchsummary, torchviz, or AST parsing.

Generate intermediate graph representation (JSON of layers + connections).

Step 2: LLM Formatting

Send intermediate graph to selected LLM via LangChain/LangGraph pipeline.

LLM tasked with generating layout and styling hints (e.g., grouping, spacing, labels).

Combine LLM output with deterministic renderer (Graphviz/NetworkX) to ensure reliability.

Step 3: User Regeneration

Provide "Regenerate with LLM" button to re-prompt the model if the diagram is unsatisfactory.

5.3 Output

Rendered interactive preview in Gradio.

Download options: PNG, PDF, JPEG, TikZ.

Style options:

Academic minimal (monochrome, clean boxes).

Annotated (with input/output sizes).

Color-coded by layer type.

6. Non-Functional Requirements

Performance: LLM-enhanced diagrams should render in < 15 seconds for medium models (≤ 100 layers).

Scalability: Must function within Hugging Face Spaces (CPU-only). Allow optional GPU acceleration locally.

Security: API keys must never be logged or persisted beyond the active session.

Fallbacks: If LLM is unavailable, diagrams should still be generated using Graphviz defaults.

Aesthetic Quality: Figures must match standards of IEEE/NeurIPS/ICML papers.

7. Technical Approach

Frontend: Gradio interface with tabs (Input Code | Preview | Regenerate | Download).

Backend:

Python parser extracts graph.

LLM workflows (LangChain/LangGraph) process and return layout/styling hints.

Graph rendered with Graphviz / TikZ exporter.

LLM Integration:

Cloud: OpenAI, Anthropic, HuggingFace Hub models.

Local: Ollama.

Deployment: Hugging Face Spaces with CPU fallback + local deployment option with Ollama.

8. Success Metrics

80% of user-submitted PyTorch models generate diagrams without errors.

70% of users rate generated diagrams as “publication-ready” without manual editing.

At least 3 export formats supported.

≥ 100 Hugging Face space likes/downloads within 3 months.

9. Future Enhancements (Stretch Goals)

Interactive diagram editing (drag-drop).

Auto-detection and grouping of common modules (ResNet blocks, Transformer encoders).

Full support for TensorFlow/Keras/JAX models.

Multi-modal diagrams (layers + dataflow with sample data).

Integration with WandB/MLFlow to visualize experiment architectures.

10. Risks & Mitigation

LLM output may be inconsistent → Always combine with deterministic rendering backend.

User privacy for API keys → Implement secure session-only storage.

Resource constraints on Hugging Face → Allow degraded mode (Graphviz-only).

Ollama dependency → Make optional, only enabled in local deployments.

11. Milestones & Timeline

– Prototype with torchviz + Gradio + regeneration button.

– Integrate LLM workflow (LangChain pipeline, OpenAI + Ollama).

– Add export options (PDF, JPEG, TikZ).

– Deploy on Hugging Face Spaces + documentation + beta release.